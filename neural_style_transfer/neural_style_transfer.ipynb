{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff6f9d2-397d-405e-9baf-ccff68691094",
   "metadata": {},
   "source": [
    "# Neural Style Transfer\n",
    "As implemented in the original *Gatys et al.* paper for celestial images and some of my favorite artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf63392-46fc-4ab9-afc5-d56b4d43bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beda6818-5842-4049-801a-3081e70bb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d90edf-b39c-49f9-a43e-71e347fe655c",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "As in *Gatys et al.* we use VGG19 convnet and preprocess accordingly to extract style and content of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fcef984-b146-47ab-822b-297f910ca475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Format and resize images to appropriate arrays\"\"\"\n",
    "    img = keras.utils.load_img(\n",
    "        image_path, target_size=(img_height, img_width))\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # preprocess for vgg19 convnet\n",
    "    img = keras.applications.vgg19.preprocess_input(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\"Reverse-engineer numpy array back to valid image format\"\"\"\n",
    "    \n",
    "    # 3 for RGB channels\n",
    "    img = img.reshape((img_height, img_width, 3))\n",
    "    \n",
    "    # zero-centering to reverse transformation from VGG19 which\n",
    "    # uses imagenet data\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    \n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "    return img\n",
    "\n",
    "def content_loss(base_img, combination_img):\n",
    "    \"\"\"computes the content loss between two images\"\"\"\n",
    "    return tf.reduce_sum(tf.square(combination_img - base_img))\n",
    "\n",
    "def gram_matrix(x):\n",
    "    \"\"\"computes the gram_matrix for a given numpy array\"\"\"\n",
    "    x = tf.transpose(x, (2, 0, 1))\n",
    "    features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
    "    gram = tf.matmul(features, tf.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style_img, combination_img):\n",
    "    \"\"\"computes the style loss between two images using gram_matrix\"\"\"\n",
    "    S = gram_matrix(style_img)\n",
    "    C = gram_matrix(combination_img)\n",
    "    channels = 3 # RGB\n",
    "    size = img_height * img_width\n",
    "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    \"\"\"regularizer for style and content loss\"\"\"\n",
    "    a = tf.square(\n",
    "        x[:, : img_height - 1, : img_width - 1, :] - x[:, 1:, : img_width - 1, :]\n",
    "    )\n",
    "    b = tf.square(\n",
    "        x[:, : img_height - 1, : img_width - 1, :] - x[:, : img_height - 1, 1:, :]\n",
    "    )\n",
    "    return tf.reduce_sum(tf.pow(a+b, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4142b-3304-4f5e-afdb-9c2d41dd7e07",
   "metadata": {},
   "source": [
    "## Defining the Final Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddba2cc5-9507-4037-832b-bbd0f533c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layer_names = [\n",
    "    \"block1_conv1\",\n",
    "    \"block2_conv1\",\n",
    "    \"block3_conv1\",\n",
    "    \"block4_conv1\",\n",
    "    \"block5_conv1\",\n",
    "]\n",
    "content_layer_name = \"block5_conv2\"\n",
    "total_variation_weight = 1e-6\n",
    "\n",
    "style_weight = 1e-6\n",
    "content_weight = 2.5e-9\n",
    "\n",
    "def compute_loss(combination_image, base_image, style_reference_image):\n",
    "    input_tensor = tf.concat(\n",
    "        [base_image, style_reference_image, combination_image], axis=0)\n",
    "    features = feature_extractor(input_tensor)\n",
    "    loss = tf.zeros(shape=())\n",
    "    layer_features = features[content_layer_name]\n",
    "    base_image_features = layer_features[0, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    loss = loss + content_weight * content_loss(\n",
    "        base_image_features, combination_features\n",
    "    )\n",
    "    for layer_name in style_layer_names:\n",
    "        layer_features = features[layer_name]\n",
    "        style_reference_features = layer_features[1, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        style_loss_value = style_loss(\n",
    "        style_reference_features, combination_features)\n",
    "        loss += (style_weight / len(style_layer_names)) * style_loss_value\n",
    "        \n",
    "    loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30485dd2-c6bc-4890-9767-dbe13c87d9c5",
   "metadata": {},
   "source": [
    "## Gradient-Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271fd2df-bb40-4206-8d81-db8ea90ea4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss_and_grads(\n",
    "    combination_image, base_image, style_reference_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(\n",
    "            combination_image, base_image, style_reference_image)\n",
    "    grads = tape.gradient(loss, combination_image)\n",
    "    return loss, grads\n",
    "\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=100.0, decay_steps=1000, decay_rate=0.8\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48080b-6769-40f5-8d85-84739409bd1b",
   "metadata": {},
   "source": [
    "## Training/Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a04850ac-80fe-46df-934d-b700fd11f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_name = \"pluto\"\n",
    "style_reference_image_name = \"signac1\"\n",
    "base_image_path = f\"images/original_images/{base_image_name}.jpg\"\n",
    "style_reference_image_path = f\"images/reference_images/{style_reference_image_name}.jpg\"\n",
    "\n",
    "original_width, original_height = keras.utils.load_img(base_image_path).size\n",
    "img_height = 800\n",
    "img_width = round(original_width * img_height / original_height)\n",
    "\n",
    "model = keras.applications.vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b529e91-a3f0-4d00-8131-16c427de0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: loss=16601.26\n",
      "Iteration 200: loss=11607.11\n",
      "Iteration 300: loss=9932.91\n",
      "Iteration 400: loss=9100.65\n",
      "Iteration 500: loss=8597.45\n",
      "Iteration 600: loss=8257.75\n",
      "Iteration 700: loss=8010.11\n",
      "Iteration 800: loss=7819.84\n",
      "Iteration 900: loss=7668.95\n",
      "Iteration 1000: loss=7545.96\n",
      "Iteration 1100: loss=7443.09\n",
      "Iteration 1200: loss=7355.37\n",
      "Iteration 1300: loss=7279.49\n",
      "Iteration 1400: loss=7213.08\n",
      "Iteration 1500: loss=7154.48\n",
      "Iteration 1600: loss=7102.37\n",
      "Iteration 1700: loss=7055.54\n",
      "Iteration 1800: loss=7013.18\n",
      "Iteration 1900: loss=6974.71\n",
      "Iteration 2000: loss=6939.46\n",
      "Iteration 2100: loss=6907.08\n",
      "Iteration 2200: loss=6877.24\n",
      "Iteration 2300: loss=6849.68\n",
      "Iteration 2400: loss=6824.11\n",
      "Iteration 2500: loss=6800.40\n",
      "Iteration 2600: loss=6778.26\n",
      "Iteration 2700: loss=6757.51\n",
      "Iteration 2800: loss=6738.09\n",
      "Iteration 2900: loss=6719.81\n",
      "Iteration 3000: loss=6702.54\n",
      "Iteration 3100: loss=6686.28\n",
      "Iteration 3200: loss=6670.93\n",
      "Iteration 3300: loss=6656.38\n",
      "Iteration 3400: loss=6642.55\n",
      "Iteration 3500: loss=6629.42\n",
      "Iteration 3600: loss=6616.91\n",
      "Iteration 3700: loss=6605.00\n",
      "Iteration 3800: loss=6593.67\n",
      "Iteration 3900: loss=6582.84\n",
      "Iteration 4000: loss=6572.48\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 36] File name too long: 'images/combination_images/[[[[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  ...\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]]]_[[[[  25.060997    19.221        5.3199997]\\n   [   7.060997    -5.7789993  -26.68     ]\\n   [  53.060997    29.221       14.32     ]\\n   ...\\n   [ -13.939003    31.221       59.32     ]\\n   [  23.060997    44.221       60.32     ]\\n   [ -82.939      -46.779      -27.68     ]]\\n\\n  [[  -9.939003    36.221       25.32     ]\\n   [  10.060997    49.221       54.32     ]\\n   [  22.060997    36.221       26.32     ]\\n   ...\\n   [  34.060997    53.221       57.32     ]\\n   [  54.060997    77.221       76.32     ]\\n   [  25.060997    59.221       73.32     ]]\\n\\n  [[  28.060997    74.221       93.32     ]\\n   [ -17.939003    32.221       75.32     ]\\n   [  10.060997    33.221       32.32     ]\\n   ...\\n   [ -18.939003    -0.7789993   -8.68     ]\\n   [  27.060997    46.221       44.32     ]\\n   [  35.060997    53.221       77.32     ]]\\n\\n  ...\\n\\n  [[  -0.939003     4.2210007  -15.68     ]\\n   [  75.061       48.221       22.32     ]\\n   [  74.061       55.221       53.32     ]\\n   ...\\n   [  31.060997    -9.778999   -10.68     ]\\n   [ -81.939       -1.7789993  118.32     ]\\n   [ -68.939      -14.778999   105.32     ]]\\n\\n  [[  33.060997     2.2210007   -5.6800003]\\n   [  33.060997    12.221001     6.3199997]\\n   [  59.060997    39.221       39.32     ]\\n   ...\\n   [  12.060997   -15.778999   -31.68     ]\\n   [ -77.939       -7.7789993  101.32     ]\\n   [ -55.939003     1.2210007  111.32     ]]\\n\\n  [[  46.060997    29.221       33.32     ]\\n   [  62.060997    26.221        4.3199997]\\n   [  72.061       29.221       17.32     ]\\n   ...\\n   [  37.060997    34.221       34.32     ]\\n   [-103.939      -64.779        4.3199997]\\n   [ -65.939      -51.779       31.32     ]]]].png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m iterations \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     18\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/combination_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle_reference_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf_env/lib/python3.9/site-packages/keras/utils/image_utils.py:361\u001b[0m, in \u001b[0;36msave_img\u001b[0;34m(path, x, data_format, file_format, scale, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe JPG format does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA images, converting to RGB.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 361\u001b[0m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf_env/lib/python3.9/site-packages/PIL/Image.py:2410\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2408\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2410\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2413\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: 'images/combination_images/[[[[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  ...\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]\\n\\n  [[-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   ...\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]\\n   [-102.939 -115.779 -122.68 ]]]]_[[[[  25.060997    19.221        5.3199997]\\n   [   7.060997    -5.7789993  -26.68     ]\\n   [  53.060997    29.221       14.32     ]\\n   ...\\n   [ -13.939003    31.221       59.32     ]\\n   [  23.060997    44.221       60.32     ]\\n   [ -82.939      -46.779      -27.68     ]]\\n\\n  [[  -9.939003    36.221       25.32     ]\\n   [  10.060997    49.221       54.32     ]\\n   [  22.060997    36.221       26.32     ]\\n   ...\\n   [  34.060997    53.221       57.32     ]\\n   [  54.060997    77.221       76.32     ]\\n   [  25.060997    59.221       73.32     ]]\\n\\n  [[  28.060997    74.221       93.32     ]\\n   [ -17.939003    32.221       75.32     ]\\n   [  10.060997    33.221       32.32     ]\\n   ...\\n   [ -18.939003    -0.7789993   -8.68     ]\\n   [  27.060997    46.221       44.32     ]\\n   [  35.060997    53.221       77.32     ]]\\n\\n  ...\\n\\n  [[  -0.939003     4.2210007  -15.68     ]\\n   [  75.061       48.221       22.32     ]\\n   [  74.061       55.221       53.32     ]\\n   ...\\n   [  31.060997    -9.778999   -10.68     ]\\n   [ -81.939       -1.7789993  118.32     ]\\n   [ -68.939      -14.778999   105.32     ]]\\n\\n  [[  33.060997     2.2210007   -5.6800003]\\n   [  33.060997    12.221001     6.3199997]\\n   [  59.060997    39.221       39.32     ]\\n   ...\\n   [  12.060997   -15.778999   -31.68     ]\\n   [ -77.939       -7.7789993  101.32     ]\\n   [ -55.939003     1.2210007  111.32     ]]\\n\\n  [[  46.060997    29.221       33.32     ]\\n   [  62.060997    26.221        4.3199997]\\n   [  72.061       29.221       17.32     ]\\n   ...\\n   [  37.060997    34.221       34.32     ]\\n   [-103.939      -64.779        4.3199997]\\n   [ -65.939      -51.779       31.32     ]]]].png'"
     ]
    }
   ],
   "source": [
    "base_image = preprocess_image(base_image_path)\n",
    "style_reference_image = preprocess_image(style_reference_image_path)\n",
    "combination_image = tf.Variable(preprocess_image(base_image_path))\n",
    "\n",
    "iterations = 4000\n",
    "for i in range(1, iterations + 1):\n",
    "    loss, grads = compute_loss_and_grads(\n",
    "        combination_image, base_image, style_reference_image\n",
    "    )\n",
    "    optimizer.apply_gradients([(grads, combination_image)])\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: loss={loss:.2f}\")\n",
    "    if i % 500 == 0:\n",
    "        img = deprocess_image(combination_image.numpy())\n",
    "        fname = f\"images/training_images/combination_image_at_iteration_{i}.png\"\n",
    "        keras.utils.save_img(fname, img)\n",
    "    if i % iterations == 0:\n",
    "        fname = f\"images/combination_images/{base_image_name}_{style_reference_image_name}.png\"\n",
    "        keras.utils.save_img(fname, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
