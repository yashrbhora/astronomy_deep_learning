{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba899d9-36a0-4eb3-9eee-c503cb437f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8580e51-2c9e-4e0d-9cdc-e8da1f72e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c71dfc-6cad-4a22-9838-e43ab132cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f109428c-d021-4309-863c-d027f5d1b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the images and labels from file\n",
    "with h5py.File('Galaxy10_DECals.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "\n",
    "# To convert the labels to categorical 10 classes\n",
    "labels = utils.to_categorical(labels, 10)\n",
    "\n",
    "# To convert to desirable type\n",
    "labels = labels.astype(np.float32)\n",
    "images = images.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1db41d9-3315-44a4-a258-64d88da0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split\n",
    "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
    "train_images, train_labels, test_images, test_labels = images[train_idx], labels[train_idx], images[test_idx], labels[test_idx]\n",
    "\n",
    "# train validation split\n",
    "train_idx, val_idx = train_test_split(np.arange(train_images.shape[0]), test_size=0.2)\n",
    "train_images, train_labels, val_images, val_labels = train_images[train_idx], train_labels[train_idx], \\\n",
    "                                                     train_images[val_idx], train_labels[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "152965e7-52d9-48a8-bd8b-8ed222cd2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac6a132-60e3-4d67-95e1-8c25243d940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9e702c-9faa-4df9-9d9b-b060af337342",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "img_shape = images.shape[1:]\n",
    "inputs = keras.Input(shape=img_shape)\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"base_galaxy_class_w_aug.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "510cc681-506d-477d-a6f5-eaa8d6dc5191",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:11:12.327212: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 10041950208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 12s 468ms/step - loss: 2.3097 - accuracy: 0.1478 - val_loss: 2.2400 - val_accuracy: 0.1434\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 2.1850 - accuracy: 0.1929 - val_loss: 6.7737 - val_accuracy: 0.1434\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 2.2261 - accuracy: 0.2192 - val_loss: 1.9491 - val_accuracy: 0.2794\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 1.9152 - accuracy: 0.2808 - val_loss: 1.8155 - val_accuracy: 0.3050\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 1.8086 - accuracy: 0.3250 - val_loss: 1.8201 - val_accuracy: 0.3069\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 1.7016 - accuracy: 0.3706 - val_loss: 1.6512 - val_accuracy: 0.3890\n",
      "Epoch 7/100\n",
      " 1/25 [>.............................] - ETA: 6s - loss: 1.5713 - accuracy: 0.4492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:12:17.192779: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-19 23:12:17.255544: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 328ms/step - loss: 1.6002 - accuracy: 0.4035 - val_loss: 1.6136 - val_accuracy: 0.4078\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 1.5310 - accuracy: 0.4361 - val_loss: 1.5473 - val_accuracy: 0.4259\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 1.4231 - accuracy: 0.4835 - val_loss: 1.5878 - val_accuracy: 0.4184\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 1.3692 - accuracy: 0.4959 - val_loss: 1.5268 - val_accuracy: 0.4400\n",
      "Epoch 11/100\n",
      " 1/25 [>.............................] - ETA: 6s - loss: 1.4168 - accuracy: 0.4902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:12:47.930307: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-19 23:12:47.993719: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 309ms/step - loss: 1.2698 - accuracy: 0.5408 - val_loss: 1.3725 - val_accuracy: 0.5177\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 1.1921 - accuracy: 0.5702 - val_loss: 1.3755 - val_accuracy: 0.5080\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 1.1428 - accuracy: 0.5885 - val_loss: 1.3736 - val_accuracy: 0.5067\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 1.0716 - accuracy: 0.6160 - val_loss: 1.5386 - val_accuracy: 0.4858\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 1.0170 - accuracy: 0.6404 - val_loss: 1.3227 - val_accuracy: 0.5462\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.9518 - accuracy: 0.6672 - val_loss: 1.2776 - val_accuracy: 0.5819\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 8s 299ms/step - loss: 0.8861 - accuracy: 0.6868 - val_loss: 1.3757 - val_accuracy: 0.5606\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.8857 - accuracy: 0.6918 - val_loss: 1.2902 - val_accuracy: 0.5678\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.7601 - accuracy: 0.7351 - val_loss: 1.2979 - val_accuracy: 0.5863\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.7463 - accuracy: 0.7418 - val_loss: 1.4833 - val_accuracy: 0.5434\n",
      "Epoch 21/100\n",
      " 1/25 [>.............................] - ETA: 6s - loss: 0.6538 - accuracy: 0.7676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:14:06.224804: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-19 23:14:06.287013: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 292ms/step - loss: 0.7000 - accuracy: 0.7484 - val_loss: 1.4483 - val_accuracy: 0.5211\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.6429 - accuracy: 0.7777 - val_loss: 1.3471 - val_accuracy: 0.5894\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.5848 - accuracy: 0.7981 - val_loss: 1.6123 - val_accuracy: 0.5296\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.5654 - accuracy: 0.8012 - val_loss: 1.5412 - val_accuracy: 0.5753\n",
      "Epoch 25/100\n",
      " 1/25 [>.............................] - ETA: 6s - loss: 0.5046 - accuracy: 0.8223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:14:37.476258: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-19 23:14:37.536772: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/25 [=>............................] - ETA: 6s - loss: 0.4933 - accuracy: 0.8242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 23:14:37.738545: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-19 23:14:37.801340: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 299ms/step - loss: 0.5314 - accuracy: 0.8154 - val_loss: 1.5105 - val_accuracy: 0.5781\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.4967 - accuracy: 0.8243 - val_loss: 1.5218 - val_accuracy: 0.5819\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.4424 - accuracy: 0.8481 - val_loss: 1.6044 - val_accuracy: 0.5653\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.4120 - accuracy: 0.8579 - val_loss: 1.8456 - val_accuracy: 0.5224\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.3834 - accuracy: 0.8655 - val_loss: 1.6128 - val_accuracy: 0.5700\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.3758 - accuracy: 0.8677 - val_loss: 1.8483 - val_accuracy: 0.5738\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.3273 - accuracy: 0.8861 - val_loss: 1.6900 - val_accuracy: 0.5509\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.3345 - accuracy: 0.8855 - val_loss: 1.6991 - val_accuracy: 0.6029\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.3009 - accuracy: 0.8943 - val_loss: 1.7352 - val_accuracy: 0.6101\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.2742 - accuracy: 0.9084 - val_loss: 1.7688 - val_accuracy: 0.5853\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.2831 - accuracy: 0.9000 - val_loss: 2.0432 - val_accuracy: 0.5882\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.2367 - accuracy: 0.9204 - val_loss: 1.8809 - val_accuracy: 0.5885\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.2273 - accuracy: 0.9210 - val_loss: 1.9129 - val_accuracy: 0.5810\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.2219 - accuracy: 0.9230 - val_loss: 1.8950 - val_accuracy: 0.5741\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.2470 - accuracy: 0.9185 - val_loss: 2.0467 - val_accuracy: 0.5969\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1751 - accuracy: 0.9413 - val_loss: 2.2116 - val_accuracy: 0.6044\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.2118 - accuracy: 0.9268 - val_loss: 1.8838 - val_accuracy: 0.6110\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1593 - accuracy: 0.9470 - val_loss: 2.1339 - val_accuracy: 0.6101\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1741 - accuracy: 0.9402 - val_loss: 2.1188 - val_accuracy: 0.6138\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1700 - accuracy: 0.9429 - val_loss: 2.1769 - val_accuracy: 0.5976\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1536 - accuracy: 0.9475 - val_loss: 2.0700 - val_accuracy: 0.6185\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1646 - accuracy: 0.9469 - val_loss: 2.3034 - val_accuracy: 0.5863\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1386 - accuracy: 0.9535 - val_loss: 2.1629 - val_accuracy: 0.6151\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1522 - accuracy: 0.9503 - val_loss: 2.4032 - val_accuracy: 0.5972\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1407 - accuracy: 0.9531 - val_loss: 2.2971 - val_accuracy: 0.5932\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1299 - accuracy: 0.9567 - val_loss: 2.1743 - val_accuracy: 0.5985\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1230 - accuracy: 0.9612 - val_loss: 2.1897 - val_accuracy: 0.5985\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1335 - accuracy: 0.9572 - val_loss: 2.1313 - val_accuracy: 0.6192\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1544 - accuracy: 0.9514 - val_loss: 2.2157 - val_accuracy: 0.6076\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1004 - accuracy: 0.9684 - val_loss: 2.6219 - val_accuracy: 0.5985\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1187 - accuracy: 0.9609 - val_loss: 2.0620 - val_accuracy: 0.6073\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.1152 - accuracy: 0.9645 - val_loss: 2.2033 - val_accuracy: 0.6195\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1080 - accuracy: 0.9646 - val_loss: 2.2356 - val_accuracy: 0.6107\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 2.1483 - val_accuracy: 0.6066\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 2.4379 - val_accuracy: 0.6201\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1017 - accuracy: 0.9696 - val_loss: 2.3579 - val_accuracy: 0.6276\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1087 - accuracy: 0.9662 - val_loss: 2.4417 - val_accuracy: 0.6038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 8s 337ms/step - loss: 0.0966 - accuracy: 0.9701 - val_loss: 2.4474 - val_accuracy: 0.6142\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.0909 - accuracy: 0.9711 - val_loss: 2.4526 - val_accuracy: 0.6154\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1040 - accuracy: 0.9682 - val_loss: 2.0254 - val_accuracy: 0.6223\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.0853 - accuracy: 0.9737 - val_loss: 2.4280 - val_accuracy: 0.5694\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.0789 - accuracy: 0.9759 - val_loss: 2.6618 - val_accuracy: 0.6292\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 7s 303ms/step - loss: 0.1023 - accuracy: 0.9680 - val_loss: 2.5033 - val_accuracy: 0.6405\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 7s 303ms/step - loss: 0.0799 - accuracy: 0.9753 - val_loss: 2.2847 - val_accuracy: 0.6326\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.0964 - accuracy: 0.9700 - val_loss: 2.2772 - val_accuracy: 0.6192\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.0842 - accuracy: 0.9742 - val_loss: 2.2406 - val_accuracy: 0.6201\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.0832 - accuracy: 0.9756 - val_loss: 2.2311 - val_accuracy: 0.6189\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.0812 - accuracy: 0.9770 - val_loss: 2.3388 - val_accuracy: 0.6176\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 2.2953 - val_accuracy: 0.6339\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.0737 - accuracy: 0.9778 - val_loss: 2.4018 - val_accuracy: 0.6117\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.0763 - accuracy: 0.9782 - val_loss: 2.3039 - val_accuracy: 0.6104\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.0795 - accuracy: 0.9742 - val_loss: 2.4161 - val_accuracy: 0.6201\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.0762 - accuracy: 0.9770 - val_loss: 2.2486 - val_accuracy: 0.6364\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 2.3573 - val_accuracy: 0.6342\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.0743 - accuracy: 0.9777 - val_loss: 2.3204 - val_accuracy: 0.6251\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 2.1353 - val_accuracy: 0.6279\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.0683 - accuracy: 0.9803 - val_loss: 2.4637 - val_accuracy: 0.6267\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.0722 - accuracy: 0.9769 - val_loss: 2.4425 - val_accuracy: 0.6223\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.0697 - accuracy: 0.9800 - val_loss: 2.6678 - val_accuracy: 0.6107\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 2.2137 - val_accuracy: 0.6461\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 2.5122 - val_accuracy: 0.6217\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.0682 - accuracy: 0.9794 - val_loss: 2.3511 - val_accuracy: 0.6351\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 2.1065 - val_accuracy: 0.6185\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.0618 - accuracy: 0.9814 - val_loss: 2.2701 - val_accuracy: 0.6204\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 2.3757 - val_accuracy: 0.6370\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.0684 - accuracy: 0.9806 - val_loss: 2.1718 - val_accuracy: 0.6427\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.0797 - accuracy: 0.9739 - val_loss: 2.1648 - val_accuracy: 0.6242\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 2.2236 - val_accuracy: 0.6304\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.0555 - accuracy: 0.9840 - val_loss: 2.2447 - val_accuracy: 0.6214\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.0628 - accuracy: 0.9810 - val_loss: 2.2293 - val_accuracy: 0.6342\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 2.5071 - val_accuracy: 0.6163\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 8s 337ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 2.3008 - val_accuracy: 0.6392\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.0604 - accuracy: 0.9839 - val_loss: 2.1975 - val_accuracy: 0.6229\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.0645 - accuracy: 0.9821 - val_loss: 1.9939 - val_accuracy: 0.6251\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.0543 - accuracy: 0.9863 - val_loss: 2.3161 - val_accuracy: 0.6423\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.0658 - accuracy: 0.9823 - val_loss: 2.9574 - val_accuracy: 0.6029\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        epochs=100,\n",
    "        batch_size=512,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9865961e-9926-4a1b-8951-adfd0447dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3676 - accuracy: 0.5366\n",
      "Test accuracy: 0.537\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\"base_galaxy_class_w_aug.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba59f5b-fe45-4d73-b604-4dda79ab1ece",
   "metadata": {},
   "source": [
    "## Trying Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5122216-4233-48a3-b206-74a61d3c4b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(256, 256, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c888304b-2aa5-4420-91b2-3be72e5e4f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 21ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 1s 30ms/step\n",
      "16/16 [==============================] - 0s 23ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "4/4 [==============================] - 1s 182ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "16/16 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "def get_feat(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels = get_feat(train_dataset)\n",
    "val_features, val_labels = get_feat(val_dataset)\n",
    "test_features, test_labels = get_feat(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ba85571-6182-4930-85c4-a6649681f046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12769, 8, 8, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea53838-efdf-4f28-95d5-798a38ee6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_tla = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc676806-f416-42d6-9574-d6f864f0dcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 93.9866 - accuracy: 0.4309 - val_loss: 37.8218 - val_accuracy: 0.4945\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 32.5169 - accuracy: 0.5744 - val_loss: 26.5428 - val_accuracy: 0.4372\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 16.4280 - accuracy: 0.6106 - val_loss: 30.1123 - val_accuracy: 0.4056\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.9547 - accuracy: 0.6339 - val_loss: 15.4315 - val_accuracy: 0.4820\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 8.6071 - accuracy: 0.6610 - val_loss: 16.2910 - val_accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 7.7222 - accuracy: 0.6853 - val_loss: 19.6466 - val_accuracy: 0.4416\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 7.2332 - accuracy: 0.7064 - val_loss: 17.3680 - val_accuracy: 0.4604\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 6.9398 - accuracy: 0.7253 - val_loss: 13.9616 - val_accuracy: 0.5340\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 6.4472 - accuracy: 0.7509 - val_loss: 19.8165 - val_accuracy: 0.4836\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 6.5649 - accuracy: 0.7658 - val_loss: 23.7805 - val_accuracy: 0.4901\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 6.2322 - accuracy: 0.7871 - val_loss: 16.9519 - val_accuracy: 0.5343\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 5.9696 - accuracy: 0.7943 - val_loss: 20.2628 - val_accuracy: 0.5346\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 6.0123 - accuracy: 0.8050 - val_loss: 26.4529 - val_accuracy: 0.5146\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 5.7650 - accuracy: 0.8226 - val_loss: 33.0706 - val_accuracy: 0.4767\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 5.8370 - accuracy: 0.8291 - val_loss: 25.5995 - val_accuracy: 0.5384\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 5.5229 - accuracy: 0.8456 - val_loss: 31.5327 - val_accuracy: 0.5224\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 5.6879 - accuracy: 0.8461 - val_loss: 31.0196 - val_accuracy: 0.5334\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 5.5877 - accuracy: 0.8547 - val_loss: 30.4824 - val_accuracy: 0.5402\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 5.3972 - accuracy: 0.8622 - val_loss: 35.3682 - val_accuracy: 0.5152\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 5.2524 - accuracy: 0.8689 - val_loss: 36.4194 - val_accuracy: 0.5277\n"
     ]
    }
   ],
   "source": [
    "model_tla.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "keras.callbacks.ModelCheckpoint(\n",
    "filepath=\"feature_extraction.keras\",\n",
    "save_best_only=True,\n",
    "monitor=\"val_loss\")\n",
    "]\n",
    "history = model_tla.fit(\n",
    "train_features, train_labels,\n",
    "epochs=20,\n",
    "validation_data=(val_features, val_labels),\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f49d75-8be1-42db-bdfc-e73c15640940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 2ms/step - loss: 7.9115 - accuracy: 0.6669\n",
      "Test accuracy: 0.667\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd0f81-3134-48fc-af2f-3ad3e8e54f0e",
   "metadata": {},
   "source": [
    "### Feature Extraction with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50fe7994-87d8-42b0-b0bb-e0cd39ff8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5348cdc6-85be-4864-a47e-4e57ce1f29ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-40GB, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3d29f88-8a34-4dad-bcb7-9b4a9a2edbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tla = keras.models.load_model(\"feature_extraction.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdc90e-0ff5-498d-b738-2c9a6b8e7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layers = model_tla.layers[1:]\n",
    "top_layers = keras.Sequential(top_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b54bfcf-5031-42c6-8c28-efc95237d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_8   (None, 256, 256, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_8 (TFOpLambd  (None, 256, 256, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 10)                8391434   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,106,122\n",
      "Trainable params: 15,470,858\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "outputs = top_layers(x)\n",
    "model_tlb = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_tlb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9037b2bf-8bca-43f1-a412-b9e2995764c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m model_tlb\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRMSprop(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m),\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      7\u001b[0m         filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_ext_w_aug.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_tlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "\n",
    "model_tlb.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_ext_w_aug.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "history = model_tlb.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68931a6-5208-4e37-bdfa-902d8d2238cc",
   "metadata": {},
   "source": [
    "## Building a mini Xception-like Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8779ade-d9d6-45d0-9353-8e49f380d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "# initializing pyramid architecture\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    \n",
    "    residual = layers.Conv2D(\n",
    "            size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_x = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac2ebf2e-536f-4503-96f2-737be24960bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 256, 256, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " rescaling_3 (Rescaling)        (None, 256, 256, 3)  0           ['sequential[3][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 252, 252, 32  2400        ['rescaling_3[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 252, 252, 32  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 252, 252, 32  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 252, 252, 32  1312       ['activation_2[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 252, 252, 32  128        ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 252, 252, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 252, 252, 32  1312       ['activation_3[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 126, 126, 32  0           ['separable_conv2d_3[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 126, 126, 32  1024        ['conv2d_4[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 126, 126, 32  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 126, 126, 32  128        ['add_1[0][0]']                  \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 126, 126, 32  0           ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 126, 126, 64  2336       ['activation_4[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 126, 126, 64  256        ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 126, 126, 64  0           ['batch_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 126, 126, 64  4672       ['activation_5[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 63, 63, 64)  0           ['separable_conv2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 63, 63, 64)   2048        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 63, 63, 64)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 63, 63, 64)  256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 63, 63, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 63, 63, 128)  8768       ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 63, 63, 128)  512        ['separable_conv2d_6[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 63, 63, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (SeparableC  (None, 63, 63, 128)  17536      ['activation_7[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0          ['separable_conv2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 128)  8192        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 128)  512        ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (SeparableC  (None, 32, 32, 256)  33920      ['activation_8[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_8[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_9 (SeparableC  (None, 32, 32, 256)  67840      ['activation_9[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0          ['separable_conv2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 256)  32768       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['add_4[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_10 (Separable  (None, 16, 16, 512)  133376     ['activation_10[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['separable_conv2d_10[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_11 (Separable  (None, 16, 16, 512)  266752     ['activation_11[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 512)   0           ['separable_conv2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 512)    131072      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 512)    0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['add_5[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           5130        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 726,474\n",
      "Trainable params: 723,466\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609d68c9-80d5-41b6-9a67-79ba70d4989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "100/100 [==============================] - 106s 1s/step - loss: 1.5273 - accuracy: 0.4488 - val_loss: 2.3955 - val_accuracy: 0.1171\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.2666 - accuracy: 0.5548 - val_loss: 2.4426 - val_accuracy: 0.1688\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.1160 - accuracy: 0.6174 - val_loss: 2.2883 - val_accuracy: 0.1591\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.0079 - accuracy: 0.6610 - val_loss: 1.8278 - val_accuracy: 0.3442\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.9344 - accuracy: 0.6931 - val_loss: 1.2075 - val_accuracy: 0.5888\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.8548 - accuracy: 0.7150 - val_loss: 1.3800 - val_accuracy: 0.4933\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.8203 - accuracy: 0.7208 - val_loss: 1.4432 - val_accuracy: 0.5496\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.7952 - accuracy: 0.7333 - val_loss: 1.0723 - val_accuracy: 0.6555\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.7611 - accuracy: 0.7418 - val_loss: 0.9443 - val_accuracy: 0.6887\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.7208 - accuracy: 0.7599 - val_loss: 0.9653 - val_accuracy: 0.6718\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.6879 - accuracy: 0.7690 - val_loss: 1.0182 - val_accuracy: 0.7091\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6816 - accuracy: 0.7715 - val_loss: 2.4695 - val_accuracy: 0.4926\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.6675 - accuracy: 0.7748 - val_loss: 1.1031 - val_accuracy: 0.6517\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6486 - accuracy: 0.7846 - val_loss: 1.2821 - val_accuracy: 0.5907\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6290 - accuracy: 0.7871 - val_loss: 1.1056 - val_accuracy: 0.6480\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6111 - accuracy: 0.7932 - val_loss: 0.8360 - val_accuracy: 0.7235\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5936 - accuracy: 0.8008 - val_loss: 1.1346 - val_accuracy: 0.6267\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5914 - accuracy: 0.8015 - val_loss: 0.9972 - val_accuracy: 0.6470\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5776 - accuracy: 0.8067 - val_loss: 0.9157 - val_accuracy: 0.6849\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5744 - accuracy: 0.8020 - val_loss: 1.0477 - val_accuracy: 0.6652\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5537 - accuracy: 0.8132 - val_loss: 1.4773 - val_accuracy: 0.6142\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.5523 - accuracy: 0.8132 - val_loss: 0.9529 - val_accuracy: 0.7103\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5413 - accuracy: 0.8172 - val_loss: 0.9468 - val_accuracy: 0.6975\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5274 - accuracy: 0.8209 - val_loss: 2.0065 - val_accuracy: 0.5437\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.5229 - accuracy: 0.8242 - val_loss: 1.0570 - val_accuracy: 0.6448\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.5082 - accuracy: 0.8295 - val_loss: 1.1609 - val_accuracy: 0.6392\n"
     ]
    }
   ],
   "source": [
    "model_x.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"mini_xception.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10,\n",
    ")\n",
    "]\n",
    "\n",
    "history = model_x.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f437934-6400-45a6-9bdd-eea83947a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 15ms/step - loss: 0.8035 - accuracy: 0.7356\n",
      "Test accuracy: 0.736\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\"mini_xception.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
